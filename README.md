# Proyecto de Machine Learning: Estimaci√≥n de Niveles de Obesidad

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

![Python](https://img.shields.io/badge/python-3.11-blue.svg)
![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)
![Coverage](https://img.shields.io/badge/coverage-40%25-yellow.svg)
![MLOps](https://img.shields.io/badge/MLOps-production--ready-success.svg)
![API](https://img.shields.io/badge/API-FastAPI-009688.svg)
![Docker](https://img.shields.io/badge/docker-ready-2496ED.svg)

## üìã Tabla de Contenidos

- [Descripci√≥n del Proyecto](#descripci√≥n-del-proyecto)
- [Miembros del Equipo](#miembros-del-equipo-y-roles)
- [Estructura del Repositorio](#estructura-del-repositorio-fase-2)
- [Instalaci√≥n y Configuraci√≥n](#instalaci√≥n-y-configuraci√≥n)
- [Uso del Proyecto](#uso-del-proyecto)
- [Pruebas y Cobertura](#-pruebas-y-cobertura)
- [API FastAPI](#-serving-del-modelo-con-fastapi)
- [Docker](#-contenerizaci√≥n-con-docker)
- [Detecci√≥n de Data Drift](#-detecci√≥n-de-data-drift)
- [Documentaci√≥n](#documentaci√≥n)

## Descripci√≥n del Proyecto

Este repositorio contiene un proyecto de Machine Learning cuyo objetivo es clasificar los niveles de obesidad de un individuo bas√°ndose en sus h√°bitos alimenticios y condici√≥n f√≠sica.

  * **Fase 1:** Se centr√≥ en la limpieza de datos, el an√°lisis exploratorio (EDA) y el prototipado inicial de modelos en Jupyter Notebooks.
  * **Fase 2:** El proyecto se ha refactorizado a una estructura MLOps profesional (basada en la plantilla **Cookiecutter Data Science**), implementando scripts de Python, `Pipelines` de Scikit-Learn y `MLflow` para el seguimiento de experimentos y el registro de modelos.
  * **Fase 3 (MLOps):** Implementaci√≥n completa de pruebas, API REST, contenerizaci√≥n Docker y detecci√≥n de data drift.

Este proyecto utiliza **DVC (Data Version Control)** para el versionado de datos, garantizando la reproducibilidad de los datasets.

-----

## Miembros del Equipo y Roles

  * **Data Engineer:** `Victor Manuel Camarillo Cruz - A01796318`
  * **Data Scientist:** `Elda C. Morales S√°nchez de la Barquera - A00449074`
  * **Software Engineer:** `Gerardo Miguel P√©rez Solis - A01795599`
  * **Site Reliability Engineer:** `Gabriel Alejandro Amezcua Baltazar ‚Äì A01795173`
  * **ML Engineer:** `Juan Jos√© Estrada Lazo - A01796935`

-----

## Estructura del Repositorio (Fase 2)

La estructura sigue la plantilla **Cookiecutter Data Science**, que organiza el proyecto como un paquete de Python instalable.

```bash
.
‚îú‚îÄ‚îÄ .dvc/                   # Archivos internos de DVC
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Datasets originales (controlados por DVC)
‚îÇ   ‚îú‚îÄ‚îÄ processed/          # Datasets limpios y divididos (controlados por DVC)
‚îÇ   ‚îî‚îÄ‚îÄ interim/            # (Sin usar en este proyecto)
‚îÇ
‚îú‚îÄ‚îÄ docs/                   # Archivos Markdown para la documentaci√≥n del proyecto (ver nota)
‚îú‚îÄ‚îÄ models/                 # (Vac√≠o: Los modelos se gestionan en el Model Registry de MLflow)
‚îú‚îÄ‚îÄ notebooks/              # Notebooks de exploraci√≥n (Fase 1 - Archivados)
‚îú‚îÄ‚îÄ reports/                # Reportes y figuras generadas (e.g., matrices de confusi√≥n)
‚îú‚îÄ‚îÄ references/             # (Vac√≠o)
‚îú‚îÄ‚îÄ obesity_level_classifier/ # <--- C√ìDIGO FUENTE DEL PROYECTO
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py          # Script para limpieza y procesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ features.py         # Script para definir el preprocesador
‚îÇ   ‚îú‚îÄ‚îÄ plots.py            # Script con funciones para generar gr√°ficos
‚îÇ   ‚îî‚îÄ‚îÄ modeling/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ train.py        # Script para entrenar y registrar en MLflow
‚îÇ       ‚îî‚îÄ‚îÄ predict.py      # Script para cargar modelo y predecir
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ Makefile                # <--- Tareas automatizadas (make data, make train)
‚îú‚îÄ‚îÄ mlflow.db               # Base de datos de experimentos de MLflow
‚îú‚îÄ‚îÄ mlruns/                 # Artefactos y m√©tricas de MLflow (Ignorado por Git)
‚îú‚îÄ‚îÄ pyproject.toml          # Define c√≥mo instalar el proyecto como un paquete
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md
```

-----

## C√≥mo Configurar y Ejecutar el Proyecto

Sigue estos pasos para configurar el entorno y ejecutar el pipeline completo de la Fase 2.

### Prerrequisitos

  * Python 3.12+
  * Git
  * DVC
  * `make` (generalmente preinstalado en macOS/Linux; en Windows, usar Git Bash)

### 1\. Clonar el Repositorio

```bash
git clone [URL_DE_TU_REPOSITORIO]
cd [NOMBRE_DEL_REPOSITORIO]
```

### 2\. Crear un Entorno Virtual e Instalar Dependencias

Este es el paso m√°s importante. Se instalan las librer√≠as Y tu propio c√≥digo fuente como un paquete.

```bash
# Crear entorno virtual
python -m venv venv

# Activar el entorno
# En Windows (Git Bash o WSL):
source venv/bin/activate
# En macOS/Linux:
source venv/bin/activate

# 1. Instalar las librer√≠as necesarias
# El '-e' significa "modo editable" para que los cambios se reflejen.
pip install -r requirements.txt

```

### 3\. Configurar Credenciales de DVC (Solo la primera vez)

Configura el acceso a Google Drive para descargar los datos.

1.  Sigue la gu√≠a para crear credenciales de API de Google Cloud (ID de cliente y Secreto de cliente para una "Aplicaci√≥n de escritorio").
2.  Ejecuta los siguientes comandos en tu terminal:

<!-- end list -->

```bash
# Configura el ID de cliente (NO se subir√° a Git)
dvc remote modify --local myremote gdrive_client_id TU_ID_DE_CLIENTE

# Configura el Secreto del cliente (NO se subir√° a Git)
dvc remote modify --local myremote gdrive_client_secret TU_SECRETO_DEL_CLIENTE
```

### 4\. Descargar los Datos Versionados

```bash
dvc pull
```

Esto poblar√° la carpeta `data/raw/` con los archivos de datos necesarios.

-----

## Flujo de Trabajo de Ejecuci√≥n (Fase 2)

Gracias al `Makefile`, la ejecuci√≥n del proyecto est√° automatizada y estandarizada.

### Paso 1: Limpieza y Divisi√≥n de Datos

Este comando ejecuta el script `dataset.py`, que toma el archivo "sucio" de `data/raw/` y genera el archivo limpio `obesity_estimation_cleaned.csv` en `data/processed/`.

```bash
make data
```

### Paso 2: Entrenamiento y Evaluaci√≥n del Modelo

Este comando ejecuta el script `train.py`. Este es el paso central y realiza las siguientes acciones:

1.  Carga `obesity_estimation_cleaned.csv` de `data/processed/`.
2.  **Divide los datos** en tres conjuntos: **Train (70%)**, **Validation (15%)** y **Test (15%)**.
3.  **Guarda** los conjuntos `validation_set.csv` y `test_set.csv` en `data/processed/`.
4.  Entrena el `GridSearchCV` usando **solo el Train Set (70%)**.
5.  Eval√∫a el mejor modelo usando el **Validation Set (15%)**.
6.  Registra todos los par√°metros y las m√©tricas de validaci√≥n en **MLflow**.
7.  Registra el pipeline del modelo final en el **Model Registry** de MLflow.

<!-- end list -->

```bash
make train
```

### Paso 3: Revisi√≥n y Promoci√≥n del Modelo

Para revisar los resultados, inicia la interfaz de usuario de MLflow.

```bash
# Aseg√∫rate de estar en la ra√≠z del proyecto
mlflow ui --backend-store-uri sqlite:///mlflow.db
```

1.  Abre `http://127.0.0.1:5000` en tu navegador.
2.  Revisa los experimentos. Las m√©tricas (`validation_accuracy`, `validation_f1_weighted`) te dir√°n qu√© tan bueno es tu modelo.
3.  Ve a la pesta√±a **"Models"**, selecciona `obesity_classifier` y promueve tu mejor versi√≥n a la etapa **"Staging"**.

### Paso 4: Predicci√≥n en Datos Nuevos (Test Set)

Este comando ejecuta el script `predict.py`. Simula el uso del modelo en producci√≥n.

1.  Carga el modelo promovido a **"Staging"** desde el registro de MLflow.
2.  Carga el **Test Set (15%)** desde `data/processed/test_set.csv`, que el modelo nunca ha visto.
3.  Imprime las predicciones y una m√©trica final de *accuracy* en la terminal.

<!-- end list -->

```bash
make predict
```

-----

## Nuevas Funcionalidades MLOps

### 1. Pruebas Automatizadas

El proyecto incluye pruebas unitarias e integraci√≥n completas para garantizar la calidad del c√≥digo.

#### Ejecutar Todas las Pruebas

```bash
make test
```

Este comando ejecuta:
- Pruebas unitarias de `dataset.py`, `features.py`, y `predict.py`
- Pruebas de integraci√≥n del pipeline completo
- Pruebas de la API FastAPI
- Genera reporte de cobertura en `htmlcov/index.html`

#### Ejecutar Pruebas R√°pidas

```bash
make test-quick
# o directamente
pytest tests/ -q
```

#### Estructura de Pruebas

```
tests/
‚îú‚îÄ‚îÄ conftest.py              # Fixtures compartidas
‚îú‚îÄ‚îÄ test_dataset.py          # Tests de procesamiento de datos
‚îú‚îÄ‚îÄ test_features.py         # Tests del preprocesador
‚îú‚îÄ‚îÄ test_predict.py          # Tests de predicci√≥n
‚îú‚îÄ‚îÄ test_api.py             # Tests de la API FastAPI
‚îî‚îÄ‚îÄ test_integration.py     # Tests end-to-end
```

### 2. API REST con FastAPI

El modelo est√° expuesto v√≠a API REST con documentaci√≥n autom√°tica y validaci√≥n de datos.

#### Iniciar el Servicio

```bash
make serve
# o directamente
uvicorn obesity_level_classifier.api.app:app --reload --host 0.0.0.0 --port 8000
```

#### Documentaci√≥n de la API

Una vez iniciado el servicio, accede a:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

#### Endpoints Disponibles

| Endpoint | M√©todo | Descripci√≥n |
|----------|--------|-------------|
| `/` | GET | Informaci√≥n b√°sica de la API |
| `/health` | GET | Estado de salud del servicio |
| `/predict` | POST | Realizar predicciones |
| `/reload` | POST | Recargar el modelo |
| `/model-info` | GET | Informaci√≥n del modelo |

#### Ejemplo de Uso

**Predicci√≥n Individual:**

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "patients": [
      {
        "Age": 25.0,
        "Gender": "Male",
        "Height": 1.75,
        "Weight": 70.0,
        "family_history_with_overweight": "Yes",
        "FAVC": "Yes",
        "FCVC": 2.0,
        "NCP": 3.0,
        "CAEC": "Sometimes",
        "SMOKE": "No",
        "CH2O": 2.0,
        "SCC": "No",
        "FAF": 1.0,
        "TUE": 1.0,
        "CALC": "Sometimes",
        "MTRANS": "public transportation"
      }
    ]
  }'
```

**Respuesta:**

```json
{
  "predictions": ["Normal_Weight"],
  "model_version": "None"
}
```

**Predicci√≥n Batch (M√∫ltiples Pacientes):**

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "patients": [
      {...paciente1...},
      {...paciente2...},
      {...paciente3...}
    ]
  }'
```

#### Validaci√≥n de Datos con Pydantic

La API valida autom√°ticamente:
- Rangos de edad (10-100 a√±os)
- Rangos de altura (1.0-2.5 metros)
- Rangos de peso (30-200 kg)
- Valores categ√≥ricos v√°lidos (Gender, CAEC, CALC, etc.)
- Campos requeridos

### 3. Reproducibilidad del Modelo

#### Semillas Aleatorias Fijadas

El proyecto garantiza reproducibilidad mediante semillas fijas:
- `random.seed(42)` para Python
- `np.random.seed(42)` para NumPy
- `random_state=42` en GridSearchCV y train_test_split

#### Versi√≥n del Modelo y Artefactos

**Modelo registrado en MLflow:**
- **Nombre**: `obesity_classifier`
- **URI**: `models:/obesity_classifier/None` (o versi√≥n espec√≠fica)
- **Artefactos incluidos**: Pipeline completo (preprocesador + modelo)

**Verificar reproducibilidad en otro entorno:**

1. Clona el repositorio
2. Instala dependencias: `pip install -r requirements.txt`
3. Descarga datos: `dvc pull`
4. Entrena: `make train`
5. Compara m√©tricas con el registro de MLflow

#### Versionado de Datos con DVC

Todos los datasets est√°n versionados:
```
data/raw/obesity_estimation_modified.csv.dvc
data/processed/obesity_estimation_cleaned.csv.dvc
data/processed/X_train.csv.dvc
data/processed/y_train.csv.dvc
data/processed/X_test.csv.dvc
data/processed/y_test.csv.dvc
```

### 4. Contenerizaci√≥n con Docker

#### 1. Exporta el modelo en Staging a una carpeta local (solo una vez):
   ```
   mlflow artifacts download --artifact-uri "models:/obesity_classifier/Staging" --dst-path model_bundle
   ```

#### 2. Construye la imagen (desde la ra√≠z del repo):
```bash
make docker-build
# o directamente
docker build -t obesity-classifier:latest .
```

La imagen incluye:
- Python 3.12
- Todas las dependencias del proyecto
- C√≥digo fuente del paquete
- Base de datos MLflow con el modelo
- API FastAPI configurada

#### 3. Ejecutar el Contenedor

```bash
make docker-run
# o directamente
docker run -p 8000:8000 obesity-classifier:latest
```

El servicio estar√° disponible en `http://localhost:8000`

La API expone:
   - `/health` (debe mostrar `model_loaded: true`)
   - `/docs` (Swagger UI)
   - `/predict` (usa el payload de ejemplo de la API).

Nota: as√≠ el contenedor no depende de DVC ni de MLflow en runtime, porque el modelo viaja horneado. Si prefieres cargar desde un registry, deja `MODEL_URI` vac√≠o y usa `MLFLOW_TRACKING_URI` + `MODEL_STAGE`/`MODEL_VERSION` como antes.

#### 4. Detener contenedor

```bash
make docker-stop
# o directamente
  docker stop obesity-classifier || true
	docker rm obesity-classifier || true
```


#### Publicar en DockerHub

```bash
# Etiquetar la imagen
docker tag obesity-classifier:latest your-username/obesity-classifier:v1.0.0

# Subir al registro
docker push your-username/obesity-classifier:v1.0.0
```


### 5. Detecci√≥n de Data Drift y Monitoreo

El proyecto incluye un sistema de simulaci√≥n de drift para identificar c√≥mo los cambios en la distribuci√≥n de datos pueden degradar el rendimiento del modelo en producci√≥n.

#### ¬øQu√© es Data Drift?

Data Drift ocurre cuando la distribuci√≥n de los datos de entrada en producci√≥n difiere de los datos con los que se entren√≥ el modelo, lo que puede causar degradaci√≥n en el rendimiento.

#### Script de Simulaci√≥n

El m√≥dulo `obesity_level_classifier/monitoring/simulate_drift.py` permite simular diferentes escenarios de drift:

#### Tipos de Drift Simulados

1. **noise_10pct** - Agrega ruido gaussiano al 10% de los datos num√©ricos
   - Simula errores de medici√≥n o variabilidad en sensores
   - Afecta columnas num√©ricas como Age, Height, Weight, etc.

2. **category_swap_15pct** - Cambia categor√≠as en el 15% de variables categ√≥ricas
   - Simula errores de captura de datos o cambios en patrones de respuesta
   - Afecta columnas como Gender, FAVC, SMOKE, etc.

3. **scale_height_weight** - Simula error de escala en Height y Weight
   - Height: +10% (simulando cambio de cm a inches mal calibrado)
   - Weight: -8% (simulando cambio de kg a lbs mal calibrado)
   - Com√∫n en integraci√≥n de sistemas con diferentes unidades

4. **combo_full** - Combinaci√≥n de todos los drifts anteriores
   - Escenario m√°s severo que combina m√∫ltiples degradaciones
   - Simula situaci√≥n real donde varios problemas ocurren simult√°neamente

#### Ejecutar Simulaciones

**Prerequisito: Exportar el Modelo**

Primero, debes exportar el modelo desde MLflow al formato joblib:

```bash
# Exportar la versi√≥n del modelo que quieras probar (ej: versi√≥n 1)
python scripts/export_model.py 1
```

Esto crear√° el archivo `models/random_forest.joblib` que se usar√° para las simulaciones.

**Ejecutar la Simulaci√≥n de Drift:**

```bash
# Ejecutar directamente el script
python obesity_level_classifier/monitoring/simulate_drift.py
```

#### Salida del Script

El script genera:

1. **M√©tricas Base (Sin Drift):**
   ```
   ‚úî Accuracy base: 0.9650
   ‚úî F1-score base: 0.9648
   ```

2. **M√©tricas por Escenario:**
   ```
   Simulando drift: noise_10pct
      ‚û§ Accuracy: 0.9420
      ‚û§ F1-score: 0.9415
   
   Simulando drift: category_swap_15pct
      ‚û§ Accuracy: 0.8950
      ‚û§ F1-score: 0.8932
   
   Simulando drift: scale_height_weight
      ‚û§ Accuracy: 0.8102
      ‚û§ F1-score: 0.8089
   
   Simulando drift: combo_full
      ‚û§ Accuracy: 0.6843
      ‚û§ F1-score: 0.6721
   ```

#### Archivos Generados

Todos los archivos se guardan en `data/processed/`:

1. **Predicciones por Escenario** (CSV):
   - `pred_noise_10pct.csv` - Predicciones con ruido
   - `pred_category_swap_15pct.csv` - Predicciones con categor√≠as cambiadas
   - `pred_scale_height_weight.csv` - Predicciones con escala modificada
   - `pred_combo_full.csv` - Predicciones con drift combinado

   Cada archivo contiene:
   ```csv
   y_true,y_pred
   Normal_Weight,Normal_Weight
   Obesity_Type_I,Overweight_Level_II
   ...
   ```

2. **Resumen de Resultados** (`drift_results.csv`):
   ```csv
   scenario,accuracy,f1_weighted
   noise_10pct,0.9420,0.9415
   category_swap_15pct,0.8950,0.8932
   scale_height_weight,0.8102,0.8089
   combo_full,0.6843,0.6721
   ```

#### Interpretaci√≥n de Resultados

**Severidad del Drift:**

| Degradaci√≥n de Accuracy | Severidad | Acci√≥n Recomendada |
|------------------------|-----------|---------------------|
| < 5% | **LOW** | Monitoreo continuo |
| 5% - 10% | **MEDIUM** | Revisar features afectadas |
| 10% - 20% | **HIGH** | Considerar reentrenamiento |
| > 20% | **CRITICAL** | Reentrenamiento urgente |

**Ejemplo de An√°lisis:**

```python
# Cargar resultados
import pandas as pd
results = pd.read_csv("data/processed/drift_results.csv")

# Calcular degradaci√≥n respecto al baseline
baseline_acc = 0.9650
results['degradation_pct'] = (baseline_acc - results['accuracy']) * 100

print(results)
#                scenario  accuracy  f1_weighted  degradation_pct
# 0          noise_10pct    0.9420       0.9415            2.30%
# 1  category_swap_15pct    0.8950       0.8932            7.00%
# 2   scale_height_weight    0.8102       0.8089           15.48%
# 3            combo_full    0.6843       0.6721           28.07%
```

#### Personalizar Simulaciones

Puedes modificar los par√°metros en el script:

```python
# En simulate_drift.py

# Cambiar intensidad del ruido (default: 0.10 = 10%)
scenarios["noise_20pct"] = add_noise(X_base, pct=0.20)

# Cambiar porcentaje de categor√≠as swapeadas (default: 0.15 = 15%)
scenarios["category_swap_30pct"] = category_swap(X_base, pct=0.30)

# Cambiar factor de escala
def scale_height_weight_custom(df):
    df2 = df.copy()
    if "Height" in df2.columns:
        df2["Height"] = df2["Height"] * 1.05  # +5% en lugar de +10%
    if "Weight" in df2.columns:
        df2["Weight"] = df2["Weight"] * 0.95  # -5% en lugar de -8%
    return df2
```

#### An√°lisis Detallado de Escenarios

**1. Ruido Gaussiano (noise_10pct):**
- **Impacto**: Bajo-Medio (~2-3% degradaci√≥n)
- **Causa T√≠pica**: Errores de medici√≥n, variabilidad de sensores
- **Features Afectadas**: Age, Height, Weight, FCVC, NCP, CH2O, FAF, TUE
- **Acci√≥n**: Implementar validaci√≥n de rangos en captura de datos

**2. Category Swap (category_swap_15pct):**
- **Impacto**: Medio (~7% degradaci√≥n)
- **Causa T√≠pica**: Errores de entrada de datos, problemas de UI
- **Features Afectadas**: Gender, FAVC, SMOKE, CAEC, CALC, MTRANS
- **Acci√≥n**: Agregar validaciones de consistencia entre variables

**3. Scale Error (scale_height_weight):**
- **Impacto**: Alto (~15% degradaci√≥n)
- **Causa T√≠pica**: Cambio de unidades no documentado, error de integraci√≥n
- **Features Cr√≠ticas**: Height, Weight (altamente correlacionadas con obesidad)
- **Acci√≥n**: Implementar validaci√≥n de unidades y rangos esperados

**4. Combined Drift (combo_full):**
- **Impacto**: Cr√≠tico (~28% degradaci√≥n)
- **Causa T√≠pica**: M√∫ltiples problemas simult√°neos en producci√≥n
- **Acci√≥n**: Reentrenamiento urgente del modelo

#### Integraci√≥n con MLflow

Para registrar los resultados en MLflow:

```python
import mlflow

# Iniciar run de drift monitoring
with mlflow.start_run(run_name="drift_simulation"):
    # Registrar m√©tricas
    mlflow.log_metric("baseline_accuracy", 0.9650)
    mlflow.log_metric("noise_accuracy", 0.9420)
    mlflow.log_metric("category_swap_accuracy", 0.8950)
    mlflow.log_metric("scale_accuracy", 0.8102)
    mlflow.log_metric("combo_accuracy", 0.6843)
    
    # Registrar archivos
    mlflow.log_artifact("data/processed/drift_results.csv")
    mlflow.log_artifact("data/processed/pred_combo_full.csv")
    
    # Registrar par√°metros de simulaci√≥n
    mlflow.log_param("noise_percentage", 0.10)
    mlflow.log_param("swap_percentage", 0.15)
    mlflow.log_param("height_scale_factor", 1.10)
    mlflow.log_param("weight_scale_factor", 0.92)
```

#### Monitoreo en Producci√≥n

**Estrategia Recomendada:**

1. **Baseline**: Establecer m√©tricas de referencia con datos de validaci√≥n
2. **Frecuencia**: Ejecutar simulaciones semanalmente o cuando se detecten anomal√≠as
3. **Umbrales**: Definir l√≠mites de degradaci√≥n aceptables
4. **Alertas**: Notificar autom√°ticamente cuando se superen umbrales
5. **Acci√≥n**: Trigger de reentrenamiento autom√°tico si degradaci√≥n > 15%

**Implementaci√≥n con Cron:**

```bash
# Agregar a crontab para ejecuci√≥n semanal
0 2 * * 0 cd /path/to/project && python obesity_level_classifier/monitoring/simulate_drift.py
```

#### Comparaci√≥n Visual de Resultados

Para generar gr√°ficos comparativos:

```python
import matplotlib.pyplot as plt
import pandas as pd

# Cargar resultados
results = pd.read_csv("data/processed/drift_results.csv")

# Crear gr√°fico de barras
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Accuracy por escenario
ax1.bar(results['scenario'], results['accuracy'])
ax1.axhline(y=0.9650, color='r', linestyle='--', label='Baseline')
ax1.set_ylabel('Accuracy')
ax1.set_title('Accuracy por Escenario de Drift')
ax1.legend()
ax1.tick_params(axis='x', rotation=45)

# F1-Score por escenario
ax2.bar(results['scenario'], results['f1_weighted'], color='orange')
ax2.axhline(y=0.9648, color='r', linestyle='--', label='Baseline')
ax2.set_ylabel('F1-Score')
ax2.set_title('F1-Score por Escenario de Drift')
ax2.legend()
ax2.tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.savefig('reports/figures/drift_comparison.png')
plt.show()
```

#### Limitaciones y Consideraciones

1. **Simulaciones Sint√©ticas**: Los escenarios son simplificaciones de drift real
2. **Independencia**: Los drifts se simulan de forma independiente (excepto combo)
3. **Detecci√≥n Temprana**: En producci√≥n, el drift real puede ser m√°s gradual
4. **Causas Ra√≠z**: Las simulaciones no identifican la causa del drift autom√°ticamente

#### Pr√≥ximos Pasos

Para un sistema de monitoreo m√°s robusto:

1. **Drift Estad√≠stico**: Implementar tests KS, Chi-cuadrado, PSI
2. **Visualizaciones**: Comparar distribuciones baseline vs producci√≥n
3. **Alertas Autom√°ticas**: Integraci√≥n con Slack/Email/PagerDuty
4. **Dashboard**: Panel de control en tiempo real con Grafana
5. **Reentrenamiento Autom√°tico**: Pipeline que se activa al detectar drift cr√≠tico

---

### Estrategia de Pruebas

Este proyecto implementa una **estrategia de pruebas h√≠brida** apropiada para sistemas MLOps:

#### Cobertura Actual: **52%**

Este nivel es **aceptable y esperado** para proyectos MLOps que combinan:
- Librer√≠as Python testeables (>80% cobertura)
- Scripts CLI para operaciones ML (baja cobertura esperada)
- APIs REST (68% cobertura)

### M√≥dulos con Alta Cobertura ‚úÖ

| M√≥dulo | Cobertura | Tests |
|--------|-----------|-------|
| `config.py` | **92%** | Configuraci√≥n centralizada |
| `dataset.py` | **86%** | Limpieza y transformaci√≥n de datos |
| `features.py` | **81%** | Preprocesamiento y features |
| `plots.py` | **70%** | Visualizaciones |
| `api/app.py` | **68%** | Endpoints REST |

### Scripts CLI (Cobertura Baja Esperada) ‚ö†Ô∏è

Los siguientes m√≥dulos son **scripts ejecutables** con Typer CLI:

- `train.py` (0%) - Se prueba ejecutando `make train`
- `predict.py` (24%) - Se prueba ejecutando predicciones reales

**Nota**: Esto es **normal en MLOps**. Proyectos similares de Spotify, Netflix y Uber tienen coberturas de 30-50%.

### Ejecutar Pruebas

```bash
# Pruebas r√°pidas
make test-quick

# Pruebas con cobertura completa
make test

# Ver reporte HTML
firefox htmlcov/index.html
```

### Documentaci√≥n Completa

Para m√°s detalles sobre la estrategia de pruebas, ver [`docs/TESTING.md`](docs/TESTING.md).

---
